{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import string\n",
    "import re\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, Embedding\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext pep8_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hun_chars = 'aábcdeéfghiíjklmnoóöőpqrstuúüűvwxyz' + '^$'  # ^,$\n",
    "\n",
    "\n",
    "def hyph_tags(word, hypher=pyphen.Pyphen(lang='hu_HU'), aslist=False):\n",
    "    \"\"\"Hyphenating classification of the characters in the word.\n",
    "    {B(egin),M(iddle),E(nd),S(ingle)}\"\"\"\n",
    "    if (len(word) == 0):\n",
    "        raise IndexError(\"0 length word\")\n",
    "    ret = list('M' * len(word))\n",
    "    ret[0] = 'B'\n",
    "    ret[-1] = 'E'\n",
    "    for i in hypher.positions(word):\n",
    "        ret[i] = 'B'\n",
    "        if(ret[i-1] == 'B'):\n",
    "            ret[i-1] = 'S'\n",
    "        else:\n",
    "            ret[i-1] = 'E'\n",
    "    if (aslist):\n",
    "        return ret\n",
    "    return \"\".join(ret)\n",
    "\n",
    "\n",
    "def hyph_tags_4to2(word, aslist=False):\n",
    "    \"\"\"{B,M,E,S} to {B, M}\"\"\"\n",
    "    ret = list(word)\n",
    "    for i in range(len(ret)):\n",
    "        if ret[i] == 'S':\n",
    "            ret[i] = 'B'\n",
    "        if ret[i] != 'B':\n",
    "            ret[i] = 'M'\n",
    "    if(aslist):\n",
    "        return ret\n",
    "    return \"\".join(ret)\n",
    "\n",
    "\n",
    "def same_char_num(word, hypher=pyphen.Pyphen(lang='hu_HU')):\n",
    "    \"\"\"Return true if the hyphenated word has as many chars as the original\"\"\"\n",
    "    return len(hypher.inserted(word)) == len(word)+len(hypher.positions(word))\n",
    "\n",
    "\n",
    "def cleaning(data):\n",
    "    \"\"\"Text cleaning:\n",
    "        lower the letters\n",
    "        punctuation, digits ellimination\"\"\"\n",
    "    formated_data = data.lower()\n",
    "    formated_data = re.sub('['+string.punctuation+']', '', formated_data)\n",
    "    formated_data = re.sub('['+string.digits+']', '', formated_data)\n",
    "    return formated_data\n",
    "\n",
    "\n",
    "# onehot: {'B','M','E','S'}\n",
    "def one_hot_encode(char, dictionary='BMES'):\n",
    "    ret = [0]*len(dictionary)\n",
    "    if char in dictionary:\n",
    "        ret[dictionary.find(char)] = 1\n",
    "        return ret\n",
    "    raise ValueError('Value out of dictionary range: '+char)\n",
    "\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    \"\"\"Randomize 2 same length array in the same permutation\"\"\"\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "\n",
    "def one_hot_decode(arr, dictionary='BMES'):\n",
    "    assert len(arr) == len(dictionary)\n",
    "    i = np.nonzero(arr)[0][0]\n",
    "    return dictionary[i]\n",
    "\n",
    "\n",
    "def generate_network_data(data, ret_input=[], ret_output=[],\n",
    "                          length=2, length_after=0,\n",
    "                          start_char='^', end_char='$',\n",
    "                          chars=hun_chars, tag_chars='BMES'):\n",
    "    \"\"\"from [word,hyph_class(word) to length-long input-output data\"\"\"\n",
    "    word = data[0]\n",
    "    word_plus = start_char*(length-length_after-1)+word+end_char*length_after\n",
    "    hyph_word = data[1]\n",
    "    for i in range(0, len(word)):\n",
    "        input_next_iter = []\n",
    "        for c in word_plus[i:i+length]:\n",
    "            input_next_iter.append(one_hot_encode(c, chars))\n",
    "        output_next_iter = one_hot_encode(hyph_word[i], tag_chars)\n",
    "        ret_input.append(input_next_iter)\n",
    "        ret_output.append(output_next_iter)\n",
    "    return\n",
    "\n",
    "def generate_network_words(data, padding=None, start_char='^',\n",
    "                           end_char='$', chars=hun_chars,\n",
    "                           tag_chars='BMES', tag_default=-1):\n",
    "    \"\"\"One-hot [word, hyph_class(word)]->[[[010],[010]],[[01],[01]]]\n",
    "    padding to fixed size, if not null\"\"\"\n",
    "    ret_input=[]\n",
    "    ret_output=[]\n",
    "    \n",
    "    word = data[0]\n",
    "    hyph_word = data[1]\n",
    "    if padding != None:\n",
    "        if len(word)>padding:\n",
    "            raise IndexError(\"The word is longer than the fixed size\")\n",
    "        else:\n",
    "            word = word + (padding-len(word))*end_char\n",
    "            hyph_word = hyph_word + (padding-len(hyph_word)) * tag_chars[tag_default]\n",
    "    for i in range(0,len(word)):\n",
    "        input_next_iter = one_hot_encode(word[i],chars)\n",
    "        output_next_iter = one_hot_encode(hyph_word[i], tag_chars)\n",
    "        ret_input.append(input_next_iter)\n",
    "        ret_output.append(output_next_iter)\n",
    "    return ret_input, ret_output\n",
    "    \n",
    "def hyph_tupples(data, hypher=pyphen.Pyphen(lang='hu_HU'),\n",
    "                tag_chars='BM'):\n",
    "    \"\"\"[words] -> [words, hyph_words]\"\"\"\n",
    "    word_list = []\n",
    "    c_all = 0\n",
    "    c_same_char_num = 0\n",
    "    for next_word in data:\n",
    "        c_all += 1\n",
    "        if(len(next_word) != 0 and same_char_num(next_word, hypher)):\n",
    "            c_same_char_num += 1\n",
    "            if(len(tag_chars) == 2):\n",
    "                word_list.append([next_word,\n",
    "                                  hyph_tags_4to2(hyph_tags(next_word))])\n",
    "            else:\n",
    "                word_list.append([next_word, hyph_tags(next_word)])\n",
    "    return word_list, c_all, c_same_char_num\n",
    "\n",
    "def tupple_to_train(word_list, window_length, length_after,\n",
    "                 tag_chars='BM'):\n",
    "    \"\"\"[words, hyph_words] -> in[0,1,0...], out[0,1,0...]\"\"\"\n",
    "    data_in = []\n",
    "    data_out = []\n",
    "    wrong_word = 0\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            generate_network_data(word, data_in, data_out,\n",
    "                                  window_length, tag_chars=tag_chars,\n",
    "                                  length_after=length_after)\n",
    "        except ValueError:\n",
    "            wrong_word += 1\n",
    "    return data_in, data_out, wrong_word\n",
    "\n",
    "def bigram_counter_from_file(filename):\n",
    "    \"\"\"creates bigram counter from file\"\"\"\n",
    "    with open(filename) as f:\n",
    "        word_list = []\n",
    "        for words in f:\n",
    "            words = words.strip()\n",
    "            words = words.split()\n",
    "            for w in words:\n",
    "                w = cleaning(w)\n",
    "                if len(w)>0:\n",
    "                    word_list.append(w)\n",
    "\n",
    "    bigram_counter = collections.Counter()\n",
    "    for word in word_list:\n",
    "        for i in range(2,len(word)):\n",
    "            bigram_counter[word[i-2:i]] += 1\n",
    "    return bigram_counter\n",
    "\n",
    "def bigrams_in_word(word, bigram_counter, mc=100):\n",
    "    bigrams = np.array(bigram_counter.most_common(mc))[:,0]\n",
    "    w_bc = len(word)-1\n",
    "    if w_bc<1:\n",
    "        return 1.0\n",
    "    w_bf = 0\n",
    "    for i in range(2,len(word)):\n",
    "        if word[i-2:i] in bigrams:\n",
    "            w_bf +=1\n",
    "    return w_bf/w_bc\n",
    "\n",
    "def bigram_selector(word, bigram_counters,threshold=0.2, mc=100):\n",
    "    \"\"\"Choose the language of the word\"\"\"\n",
    "    lang_likes = np.zeros(len(bigram_counters)+1)\n",
    "    for i in range(0,len(bigram_counters)):\n",
    "        lang_likes[i] = bigrams_in_word(word, bigram_counters[i], mc)\n",
    "    lang_likes_max = np.argmax(lang_likes)\n",
    "    \n",
    "    for i in range(0,len(bigram_counters)):\n",
    "        if i!=lang_likes_max:\n",
    "            if lang_likes[lang_likes_max]-lang_likes[i]<=threshold:\n",
    "                return len(bigram_counters)\n",
    "    return lang_likes_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_reader(file, tail_cut=100000,\n",
    "                lang_selector = False, lang_thr=0.6,\n",
    "                lang_file_en='../wikipedia/angol/ossz_angol',\n",
    "                lang_file_hu='../wikipedia/magyar/ossz_magyar'):\n",
    "    \"\"\"Read data from file\"\"\"\n",
    "\n",
    "    if lang_selector:\n",
    "        bigram_counter_en = bigram_counter_from_file(lang_file_en)\n",
    "        bigram_counter_hu = bigram_counter_from_file(lang_file_hu)\n",
    "        out_en_words = 0\n",
    "    \n",
    "    tail_cut_ptest_words = tail_cut + 500\n",
    "\n",
    "    counter_hu_data = collections.Counter()\n",
    "    with open(file, 'r',\n",
    "              errors='ignore', encoding='latin2') as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            i = i+1\n",
    "            words = line.split()\n",
    "            if len(words) > 1:\n",
    "                if(words[1].isdigit()):\n",
    "                    cword = cleaning(words[0])\n",
    "                    if lang_selector:\n",
    "                        lang = bigram_selector(cword,\n",
    "                                            [bigram_counter_hu,\n",
    "                                             bigram_counter_en],\n",
    "                                            lang_thr)\n",
    "                        if (lang!=1):\n",
    "                            counter_hu_data[cword] += int(words[1])\n",
    "                        else:\n",
    "                            out_en_words +=1\n",
    "                    else:\n",
    "                        counter_hu_data[cword] += int(words[1])\n",
    "            if i > tail_cut_ptest_words:\n",
    "                break\n",
    "    if lang_selector:\n",
    "        print(\"Throwed english words: \", out_en_words)\n",
    "    return counter_hu_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_data_generator(data_counter, window_length, length_after,\n",
    "                         tag_chars='BM', tail_cut=100000,\n",
    "                         valid_rate=0.2, test_rate=0.1):\n",
    "    \"\"\"Generate training data from counter data\n",
    "    unique words -> characters -> randomize -> cut\"\"\"\n",
    "\n",
    "    data_list = np.array(data_counter.most_common(tail_cut))[:,0]\n",
    "    word_list, c_all, c_same_char_num = hyph_tupples(data_list,\n",
    "                                                    tag_chars=tag_chars)\n",
    "    print('Data read successfully')\n",
    "    print('non-standard hyphenation:')\n",
    "    print(c_same_char_num, c_all, c_same_char_num/c_all)\n",
    "\n",
    "    # Generate network data\n",
    "    data_in = []\n",
    "    data_out = []\n",
    "    wrong_word = 0\n",
    "    data_in, data_out, wrong_word = tupple_to_train(word_list,\n",
    "                                                    window_length,\n",
    "                                                    length_after,\n",
    "                                                    tag_chars=tag_chars)\n",
    "    print('Data len: ', len(data_in))\n",
    "    print('Words with unrecognized caracter: ', wrong_word)\n",
    "\n",
    "    data_len = len(data_in)\n",
    "\n",
    "    data_in = np.array(data_in, dtype='float32')\n",
    "    data_out = np.array(data_out, dtype='float32')\n",
    "    data_in, data_out = unison_shuffled_copies(data_in, data_out)\n",
    "    tests_input = data_in[0:int(data_len*test_rate)]\n",
    "    tests_target = data_out[0:int(data_len*test_rate)]\n",
    "    valid_input = data_in[int(data_len*test_rate):\n",
    "                          int(data_len*(test_rate+valid_rate))]\n",
    "    valid_target = data_out[int(data_len*test_rate):\n",
    "                            int(data_len*(test_rate+valid_rate))]\n",
    "    train_input = data_in[int(data_len*(test_rate+valid_rate)):]\n",
    "    train_target = data_out[int(data_len*(test_rate+valid_rate)):]\n",
    "\n",
    "    print('Training data size:', np.shape(train_input), np.shape(train_target))\n",
    "    print('Validation data size:', np.shape(valid_input),\n",
    "          np.shape(valid_target))\n",
    "    print('Test data size:', np.shape(tests_input), np.shape(tests_target))\n",
    "\n",
    "    train_input_flatten = np.reshape(\n",
    "        train_input, (len(train_input), (window_length)*len(hun_chars)))\n",
    "    valid_input_flatten = np.reshape(\n",
    "        valid_input, (len(valid_input), (window_length)*len(hun_chars)))\n",
    "    tests_input_flatten = np.reshape(\n",
    "        tests_input, (len(tests_input), (window_length)*len(hun_chars)))\n",
    "    print('Network data generated successfully')\n",
    "\n",
    "    return [train_input_flatten, train_target,\n",
    "            valid_input_flatten, valid_target,\n",
    "            tests_input_flatten, tests_target]\n",
    "\n",
    "\n",
    "def train_data_generator_uwords(data_counter, window_length, length_after,\n",
    "                                tag_chars='BM', tail_cut=100000,\n",
    "                                valid_rate=0.2, test_rate=0.1):\n",
    "    \"\"\"Generate training data from counter data\n",
    "        unique words -> randomize -> cut -> characters\"\"\"\n",
    "    data_list = np.array(data_counter.most_common(tail_cut))[:,0]\n",
    "    np.random.shuffle(data_list)\n",
    "    data_len = len(data_list)\n",
    "    tests_data = data_list[0:int(data_len*test_rate)]\n",
    "    valid_data = data_list[int(data_len*test_rate):\n",
    "                           int(data_len*(test_rate+valid_rate))]\n",
    "    train_data = data_list[int(data_len*(test_rate+valid_rate)):]\n",
    "    \n",
    "    c_all = 0\n",
    "    c_same_char_num = 0\n",
    "    tests_list, c_all_p, c_same_char_num_p = hyph_tupples(tests_data,\n",
    "                                                          tag_chars=tag_chars)\n",
    "    c_all += c_all_p\n",
    "    c_same_char_num += c_same_char_num_p\n",
    "    valid_list, c_all_p, c_same_char_num_p = hyph_tupples(valid_data,\n",
    "                                                          tag_chars=tag_chars)\n",
    "    c_all += c_all_p\n",
    "    c_same_char_num += c_same_char_num_p\n",
    "    train_list, c_all_p, c_same_char_num_p = hyph_tupples(train_data,\n",
    "                                                          tag_chars=tag_chars)\n",
    "    c_all += c_all_p\n",
    "    c_same_char_num += c_same_char_num_p\n",
    "    \n",
    "    print('Data read successfully')\n",
    "    print('non-standard hyphenation:')\n",
    "    print(c_same_char_num, c_all, c_same_char_num/c_all)\n",
    "    \n",
    "    wrong_word = 0\n",
    "    tests_input, tests_target, wrong_w_p = tupple_to_train(tests_list,\n",
    "                                                           window_length,\n",
    "                                                           length_after,\n",
    "                                                           tag_chars=tag_chars)\n",
    "    wrong_word += wrong_w_p\n",
    "    valid_input, valid_target, wrong_w_p = tupple_to_train(valid_list,\n",
    "                                                           window_length,\n",
    "                                                           length_after,\n",
    "                                                           tag_chars=tag_chars)\n",
    "    wrong_word += wrong_w_p\n",
    "    train_input, train_target, wrong_w_p = tupple_to_train(train_list,\n",
    "                                                           window_length,\n",
    "                                                           length_after,\n",
    "                                                           tag_chars=tag_chars)\n",
    "    wrong_word += wrong_w_p\n",
    "    print('Words with unrecognized caracter: ', wrong_word)\n",
    "\n",
    "    print('Training data size:', np.shape(train_input), np.shape(train_target))\n",
    "    print('Validation data size:', np.shape(valid_input),\n",
    "          np.shape(valid_target))\n",
    "    print('Test data size:', np.shape(tests_input), np.shape(tests_target))\n",
    "\n",
    "    train_input_flatten = np.reshape(\n",
    "        train_input, (len(train_input), (window_length)*len(hun_chars)))\n",
    "    valid_input_flatten = np.reshape(\n",
    "        valid_input, (len(valid_input), (window_length)*len(hun_chars)))\n",
    "    tests_input_flatten = np.reshape(\n",
    "        tests_input, (len(tests_input), (window_length)*len(hun_chars)))\n",
    "    print('Network data generated successfully')\n",
    "\n",
    "    return [train_input_flatten, train_target,\n",
    "            valid_input_flatten, valid_target,\n",
    "            tests_input_flatten, tests_target]\n",
    "    \n",
    "\n",
    "def train_data_generator_uchars(data_counter, window_length, length_after,\n",
    "                                tag_chars='BM', tail_cut=100000,\n",
    "                                valid_rate=0.2, test_rate=0.1):\n",
    "    \"\"\"Generate training data from counter data\n",
    "        unique words -> characters -> unique -> randomize -> cut\"\"\"\n",
    "    data_list = np.array(data_counter.most_common(tail_cut))[:,0]\n",
    "    word_list, c_all, c_same_char_num = hyph_tupples(data_list,\n",
    "                                                    tag_chars=tag_chars)\n",
    "    print('Data read successfully')\n",
    "    print('non-standard hyphenation:')\n",
    "    print(c_same_char_num, c_all, c_same_char_num/c_all)\n",
    "\n",
    "    # Generate network data\n",
    "    data_in = []\n",
    "    data_out = []\n",
    "    wrong_word = 0\n",
    "    data_in, data_out, wrong_word = tupple_to_train(word_list,\n",
    "                                                    window_length,\n",
    "                                                    length_after,\n",
    "                                                    tag_chars=tag_chars)\n",
    "    print('Data len: ', len(data_in))\n",
    "    print('Words with unrecognized caracter: ', wrong_word)\n",
    "\n",
    "    #Unique\n",
    "    data_len = len(data_in)\n",
    "\n",
    "    data_in = np.array(data_in, dtype='float32')\n",
    "    data_out = np.array(data_out, dtype='float32')\n",
    "    \n",
    "    shape_in = np.shape(data_in)\n",
    "    shape_out = np.shape(data_out)\n",
    "    \n",
    "    data_in_flatten = np.reshape(\n",
    "        data_in, (shape_in[0], shape_in[1]*shape_in[2]))\n",
    "    shape_in_flatten = np.shape(data_in_flatten)\n",
    "    \n",
    "    data_iosum = np.concatenate((data_in_flatten, data_out), axis=1)\n",
    "    data_iosum_unique = np.vstack({tuple(row) for row in data_iosum})\n",
    "    \n",
    "    data_in = data_iosum_unique[:,:-shape_out[1]]\n",
    "    data_out = data_iosum_unique[:,-shape_out[1]:]\n",
    "    print('Data unique len: ', np.shape(data_iosum_unique)[0])\n",
    "    \n",
    "    data_len = len(data_in)\n",
    "    data_in, data_out = unison_shuffled_copies(data_in, data_out)\n",
    "    tests_input = data_in[0:int(data_len*test_rate)]\n",
    "    tests_target = data_out[0:int(data_len*test_rate)]\n",
    "    valid_input = data_in[int(data_len*test_rate):\n",
    "                          int(data_len*(test_rate+valid_rate))]\n",
    "    valid_target = data_out[int(data_len*test_rate):\n",
    "                            int(data_len*(test_rate+valid_rate))]\n",
    "    train_input = data_in[int(data_len*(test_rate+valid_rate)):]\n",
    "    train_target = data_out[int(data_len*(test_rate+valid_rate)):]\n",
    "\n",
    "    print('Training data size:', np.shape(train_input), np.shape(train_target))\n",
    "    print('Validation data size:', np.shape(valid_input),\n",
    "          np.shape(valid_target))\n",
    "    print('Test data size:', np.shape(tests_input), np.shape(tests_target))\n",
    "\n",
    "    train_input_flatten = np.reshape(\n",
    "        train_input, (len(train_input), (window_length)*len(hun_chars)))\n",
    "    valid_input_flatten = np.reshape(\n",
    "        valid_input, (len(valid_input), (window_length)*len(hun_chars)))\n",
    "    tests_input_flatten = np.reshape(\n",
    "        tests_input, (len(tests_input), (window_length)*len(hun_chars)))\n",
    "    print('Network data generated successfully')\n",
    "\n",
    "    return [train_input_flatten, train_target,\n",
    "            valid_input_flatten, valid_target,\n",
    "            tests_input_flatten, tests_target]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_data_words(data_counter, tag_chars='BM', padding = 30, tail_cut=100000,\n",
    "                     valid_rate=0.2, test_rate=0.1):\n",
    "    \"\"\"Training data, example: alma -> {[[1,0..][0,0..][0,0...][0,0...]],[[1,0],[0,1][1,0][0,1]]}\"\"\"\n",
    "    data_list = np.array(data_counter.most_common(tail_cut))[:,0]\n",
    "    word_list, c_all, c_same_char_num = hyph_tupples(data_list,\n",
    "                                                    tag_chars=tag_chars)\n",
    "    print('Data read successfully')\n",
    "    print('non-standard hyphenation:')\n",
    "    print(c_same_char_num, c_all, c_same_char_num/c_all)\n",
    "    \n",
    "    # Generate network data\n",
    "    data_in = []\n",
    "    data_out = []\n",
    "    wrong_word = 0\n",
    "    long_word = 0\n",
    "    for word in word_list:\n",
    "        try:\n",
    "            next_data_in, next_data_out = generate_network_words(word, padding = padding, tag_chars=tag_chars)\n",
    "            next_data_in = np.array(next_data_in, dtype='float32')\n",
    "            next_data_out = np.array(next_data_out, dtype='float32')\n",
    "            data_in.append(next_data_in)\n",
    "            data_out.append(next_data_out)\n",
    "        except ValueError:\n",
    "            wrong_word += 1\n",
    "        except IndexError:\n",
    "            long_word += 1\n",
    "            \n",
    "    print('Data len: ', len(data_in))\n",
    "    print('Words with unrecognized caracter: ', wrong_word)\n",
    "    print('Words longer than the padding: ', long_word)\n",
    "    \n",
    "    data_in = np.array(data_in)\n",
    "    data_out = np.array(data_out)\n",
    "    \n",
    "    data_len = len(data_in)\n",
    "    data_in, data_out = unison_shuffled_copies(data_in, data_out)\n",
    "    \n",
    "    datas = {}\n",
    "    \n",
    "    datas[\"tests_input\"] = data_in[0:int(data_len*test_rate)]\n",
    "    datas[\"tests_target\"] = data_out[0:int(data_len*test_rate)]\n",
    "    datas[\"valid_input\"] = data_in[int(data_len*test_rate):\n",
    "                                   int(data_len*(test_rate+valid_rate))]\n",
    "    datas[\"valid_target\"] = data_out[int(data_len*test_rate):\n",
    "                                     int(data_len*(test_rate+valid_rate))]\n",
    "    datas[\"train_input\"] = data_in[int(data_len*(test_rate+valid_rate)):]\n",
    "    datas[\"train_target\"] = data_out[int(data_len*(test_rate+valid_rate)):]\n",
    "    \n",
    "    return datas, wrong_word, long_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(data_in[0:10],data_out[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_creator_dnn(window_length, output_length, num_layers=1,\n",
    "                  num_hidden=10, chars=hun_chars):\n",
    "    \"\"\"Creates Keras model with the given input, output dimensions\n",
    "    and layer number, hidden layer length\"\"\"\n",
    "    \n",
    "    input_shape = window_length*len(chars)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(input_dim=(input_shape),\n",
    "                    units=num_hidden, name='input_layer',\n",
    "                    activation='sigmoid'))\n",
    "    for i in range(1, num_layers):\n",
    "        model.add(Dense(units=num_hidden, activation='sigmoid'))\n",
    "\n",
    "    # model.add(Flatten())\n",
    "    model.add(Dense(output_length, name='output_layer', activation='softmax'))\n",
    "\n",
    "    if(output_length == 2):\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    else:\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def model_creator_cnn(output_length,kernel_size=10, strides=1, word_length = 30, chars=hun_chars):\n",
    "    \"\"\"Creates Keras CNN model\"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(516,kernel_size, strides=strides, padding=\"same\",\n",
    "                     activation='relu', input_shape=(word_length, len(chars))))\n",
    "    \n",
    "\n",
    "\n",
    "    model.add(Dense((output_length), name = 'output_layer', activation='softmax'))\n",
    "    \n",
    "    if(output_length == 2):\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    else:\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read successfully\n",
      "non-standard hyphenation:\n",
      "82563 83678 0.9866751117378523\n",
      "Data len:  81910\n",
      "Words with unrecognized caracter:  646\n",
      "Words longer than the padding:  7\n",
      "(57337, 30, 37) (16382, 30, 37) (8191, 30, 37)\n"
     ]
    }
   ],
   "source": [
    "padding = 30\n",
    "tail_cut = 100000\n",
    "window_length = 7\n",
    "length_after = 3\n",
    "tag_chars = 'BM'\n",
    "num_layers = 5\n",
    "num_hidden = 110\n",
    "\n",
    "# Data read and network data generate\n",
    "counter_hu_data = data_reader('web2.2-freq-sorted.txt',tail_cut, lang_selector=False)\n",
    "\n",
    "datas, wrong_words, long_word = train_data_words(counter_hu_data, tag_chars,\n",
    "                                                             padding, tail_cut)\n",
    "\n",
    "tests_input_cnn = datas[\"tests_input\"]\n",
    "tests_target_cnn = datas[\"tests_target\"]\n",
    "valid_input_cnn = datas[\"valid_input\"]\n",
    "valid_target_cnn = datas[\"valid_target\"]\n",
    "train_input_cnn = datas[\"train_input\"]\n",
    "train_target_cnn = datas[\"train_target\"]\n",
    "\n",
    "print(np.shape(train_input_cnn), np.shape(valid_input_cnn), np.shape(tests_input_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read successfully\n",
      "non-standard hyphenation:\n",
      "82563 83678 0.9866751117378523\n",
      "Words with unrecognized caracter:  646\n",
      "Training data size: (488431, 7, 37) (488431, 2)\n",
      "Validation data size: (139952, 7, 37) (139952, 2)\n",
      "Test data size: (69926, 7, 37) (69926, 2)\n",
      "Network data generated successfully\n"
     ]
    }
   ],
   "source": [
    "tail_cut = 100000\n",
    "window_length = 7\n",
    "length_after = 3\n",
    "tag_chars = 'BM'\n",
    "num_layers = 5\n",
    "num_hidden = 110\n",
    "\n",
    "# Data read and network data generate\n",
    "counter_hu_data = data_reader('web2.2-freq-sorted.txt',tail_cut, lang_selector=False)\n",
    "[train_input_flatten, train_target,\n",
    " valid_input_flatten, valid_target,\n",
    " tests_input_flatten,\n",
    " tests_target] = train_data_generator_uwords(counter_hu_data,\n",
    "                                             window_length,\n",
    "                                             length_after,\n",
    "                                             tag_chars,\n",
    "                                             tail_cut)\n",
    "\n",
    "#train_input_flatten_p1 = np.expand_dims(train_input_flatten, axis=1) # reshape (X, 1, 259) \n",
    "#valid_input_flatten_p1 = np.expand_dims(valid_input_flatten, axis=1)\n",
    "#tests_input_flatten_p1 = np.expand_dims(tests_input_flatten, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models created. Start training\n"
     ]
    }
   ],
   "source": [
    "# Creating the keras model\n",
    "model_dnn = model_creator_dnn(window_length, len(tag_chars),\n",
    "                      num_layers, num_hidden)\n",
    "\n",
    "earlyStopping_dnn = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=20, verbose=0, mode='auto')\n",
    "\n",
    "model_cnn = model_creator_cnn(len(tag_chars))\n",
    "\n",
    "earlyStopping_cnn = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "\n",
    "print('Models created. Start training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f0425cd985d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names)\u001b[0m\n\u001b[1;32m     98\u001b[0m                \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                show_layer_names=True):\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     18\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model_cnn, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history_cnn = model_cnn.fit(train_input_cnn, train_target_cnn,\n",
    "                    epochs=1, batch_size=1024,\n",
    "                    validation_data=(valid_input_cnn, valid_target_cnn),\n",
    "                    verbose=0, callbacks=[earlyStopping_cnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-23bc9086eb86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_input_flatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     verbose=0, callbacks=[earlyStopping_dnn])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_dnn = model_dnn.fit(train_input_flatten, train_target,\n",
    "                    epochs=1000, batch_size=1024,\n",
    "                    validation_data=(valid_input_flatten, valid_target),\n",
    "                    verbose=0, callbacks=[earlyStopping_dnn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABE4AAAHUCAYAAAAk+W0OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsHAiSZIkSZLUh4UTSZIkSZKkPv4NWwHjhdXuViQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f36ca1d5780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.figure(figsize=(13, 5))\n",
    "plt.plot(history_cnn.history['loss'])\n",
    "plt.plot(history_cnn.history['val_loss'])\n",
    "\n",
    "#plt.plot(history_dnn.history['loss'])\n",
    "#plt.plot(history_dnn.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['cnn_train', 'cnn_validation', 'dnn_train', 'dnn_validation'], loc='upper right')\n",
    "plt.ylim((0.0, 0.02))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('models/mBM7uwordsNo2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tests_input_flatten' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-14208a2905e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dnn\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtest_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_dnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests_input_flatten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tests_input_flatten' is not defined"
     ]
    }
   ],
   "source": [
    "model_type = \"dnn\"\n",
    "\n",
    "test_tp = 0\n",
    "test_fp = 0\n",
    "test_tn = 0\n",
    "test_fn = 0\n",
    "test_str = \"\"\n",
    "\n",
    "if model_type == \"dnn\":\n",
    "    test_results = model_dnn.predict(tests_input_flatten)\n",
    "    history = history_dnn\n",
    "else:\n",
    "    if model_type == \"cnn\":\n",
    "        test_results = model_cnn.predict(tests_input_flatten_p1)\n",
    "        history = history_cnn\n",
    "if(np.shape(test_results)[1] == 2):\n",
    "    for i in range(len(test_results)):\n",
    "        # positive\n",
    "        if np.argmax(test_results[i]) == 1:\n",
    "            if np.argmax(tests_target[i]) == 1:\n",
    "                test_tn += 1\n",
    "            else:\n",
    "                test_fn += 1\n",
    "        else:\n",
    "            if np.argmax(tests_target[i]) == 1:\n",
    "                test_fp += 1\n",
    "            else:\n",
    "                test_tp += 1\n",
    "    print(np.shape(test_results),np.shape(tests_target))\n",
    "    print(test_tp,test_fp,test_tn,test_fn)\n",
    "    test_precision = test_tp / (test_tp + test_fp)\n",
    "    test_recall = test_tp / (test_tp + test_fn)\n",
    "    test_Fscore = 2 * (test_precision * \n",
    "                       test_recall) / (test_precision + test_recall)\n",
    "    test_str = str(test_precision) + '\\t' + str(test_recall) \n",
    "    test_str += '\\t' + str(test_Fscore)\n",
    "else:\n",
    "    for i in range(len(test_results)):\n",
    "        if np.argmax(test_results[i]) == np.argmax(tests_target[i]):\n",
    "            test_success += 1\n",
    "        else:\n",
    "            test_fail += 1\n",
    "    test_str = str(test_fail/(test_fail+test_success))\n",
    "\n",
    "with open(\"results_models.txt\", \"a\") as myfile:\n",
    "    result = \"\"\n",
    "#    result += str(window_length) + '\\t'\n",
    "#    result += str(length_after) + '\\t' + tag_chars\n",
    "#    result += '\\t' + str(num_layers) + '\\t'\n",
    "#    result += str(num_hidden) + '\\t'\n",
    "    result += model_type + '\\t'\n",
    "    result += str(history.epoch[-1]) + '\\t'\n",
    "    result += str(history.history['val_loss'][-1])\n",
    "    result += '\\t' + test_str\n",
    "    result += '\\n'\n",
    "    myfile.write(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hyph_predict(word, model,\n",
    "                 length=2, length_after=0, tag_chars='BMES', aslist=False, model_type='dnn'):\n",
    "    \"\"\"Generate tagging from the input word according to the model\"\"\"\n",
    "    word_in = []\n",
    "    word_out = []\n",
    "    generate_network_data([word, len(word)*tag_chars[0]],\n",
    "                          word_in, word_out, length=length,\n",
    "                          length_after=length_after, tag_chars=tag_chars)\n",
    "    word_in = np.reshape(word_in, (len(word_in), (length)*len(hun_chars)))\n",
    "    if model_type=='cnn':\n",
    "        word_in = np.expand_dims(word_in, axis=1) # reshape (x, 1, 259) \n",
    "    word_out = model.predict(word_in)\n",
    "    tag_list = np.array(list(tag_chars))\n",
    "    temp = np.argmax(word_out, axis=1)\n",
    "    temp = tag_list[temp]\n",
    "    if(aslist):\n",
    "        return temp\n",
    "    return \"\".join(temp)\n",
    "def hyph_insterted(word, model,\n",
    "                   length=2, length_after=0, tag_chars='BMES', model_type='dnn'):\n",
    "    tags = hyph_predict(word, model,length,\n",
    "                        length_after, tag_chars, aslist=False, model_type=model_type)\n",
    "    word_inserted = \"\"\n",
    "    if tag_chars=='BM':\n",
    "        for i in range(len(word)):\n",
    "            if i != 0 and tags[i]=='B':\n",
    "                word_inserted += '-'\n",
    "            word_inserted += word[i]\n",
    "    else:\n",
    "        raise NotImplementedError('BM implemented only')\n",
    "    return word_inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypher = pyphen.Pyphen(lang='hu_HU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: szemüveg Prediction: BMMMBMMM Target: BMMMBMMM szem-üveg\n",
      "Word: leopárd Prediction: BMBMMMM Target: BMBBMMM le-o-párd\n"
     ]
    }
   ],
   "source": [
    "test = 'szemüveg'\n",
    "print('Word:', test, 'Prediction:',\n",
    "      hyph_predict(test, model, window_length, length_after, tag_chars, model_type='cnn'),\n",
    "      'Target:', hyph_tags_4to2(hyph_tags(test)), hypher.inserted(test))\n",
    "\n",
    "test = 'leopárd'\n",
    "print('Word:', test, 'Prediction:',\n",
    "      hyph_predict(test, model, window_length, length_after, tag_chars, model_type='cnn'),\n",
    "      'Target:', hyph_tags_4to2(hyph_tags(test)), hypher.inserted(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\tTarget\n",
      "cros-so-ver \t cros-sover\n",
      "li-ech-ten-s-tein \t liech-tens-tein\n",
      "Value out of dictionary range: ô\n",
      "hau-s-er \t ha-user\n",
      "szak-ta-ná-cs-adás-sal \t szak-ta-nács-adás-sal\n",
      "fo-gadó-órát \t fo-ga-dó-órát\n",
      "té-nyező-re \t té-nye-ző-re\n",
      "Value out of dictionary range: ô\n",
      "Value out of dictionary range: ä\n",
      "ta-ná-cs-adót \t ta-nács-adót\n",
      "ar-ing \t aring\n",
      "Value out of dictionary range: ô\n",
      "Value out of dictionary range: ô\n",
      "Value out of dictionary range: ă\n",
      "sci-en-ti-a-rum \t sci-en-tia-rum\n"
     ]
    }
   ],
   "source": [
    "test_words = counter_hu_data.most_common()[-400:]\n",
    "print('Prediction\\tTarget')\n",
    "for word in test_words:\n",
    "    next_word = word[0]\n",
    "    if(len(next_word) != 0 and same_char_num(next_word)):\n",
    "        try:\n",
    "            predicted_value = hyph_predict(next_word, model,\n",
    "                                           window_length, length_after,\n",
    "                                           tag_chars, model_type='cnn')\n",
    "            predicted_visual = hyph_insterted(next_word, model,\n",
    "                                              window_length, length_after,\n",
    "                                              tag_chars, model_type='cnn')\n",
    "            excepted_value = hyph_tags_4to2(hyph_tags(next_word))\n",
    "            success = predicted_value == excepted_value\n",
    "            if not success:\n",
    "                print(predicted_visual,\n",
    "                        '\\t',hypher.inserted(next_word))\n",
    "        except ValueError as e:\n",
    "            print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypher = pyphen.Pyphen(lang='hu_HU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(counter_hu_data.most_common(100))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in hypher.iterate('almáspite'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def part_hyph(word):\n",
    "    pos = hypher.positions(word)\n",
    "    if len(pos)<1:\n",
    "        return\n",
    "    if len(pos)+2==len(re.findall('[aáeéiíoóöőuúüű]',word)):\n",
    "        return\n",
    "    hyphs = []\n",
    "    hyphs.append(word[:pos[0]])\n",
    "    for i in range(len(pos)-1):\n",
    "        hyphs.append(word[pos[i]:pos[i+1]])\n",
    "    hyphs.append(word[pos[-1]:])\n",
    "    for part in hyphs:\n",
    "        mgh = len(re.findall('[aáeéiíoóöőuúüű]',part))\n",
    "        if(mgh>1):\n",
    "            part_hyph = hypher.inserted(part)\n",
    "            if len(part)<len(part_hyph):\n",
    "                print(hypher.inserted(word), part_hyph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word in np.array(counter_hu_data.most_common(100000))[:,0]:\n",
    "    part_hyph(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(re.findall('[aáeéiíoóöőuúüű]','üveg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_counter_en = bigram_counter_from_file('../wikipedia/angol/ossz_angol')\n",
    "bigram_counter_hu = bigram_counter_from_file('../wikipedia/magyar/ossz_magyar')\n",
    "print(len(bigram_counter_en.most_common()))\n",
    "print(len(bigram_counter_hu.most_common()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_word = 'kabátgomb'\n",
    "print(bigrams_in_word(test_word, bigram_counter_en))\n",
    "print(bigrams_in_word(test_word, bigram_counter_hu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = np.array(counter_hu_data.most_common(100000))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hu_w = 0\n",
    "en_w = 0\n",
    "idk_w = 0\n",
    "for w in words:\n",
    "    hu_like = bigrams_in_word(w, bigram_counter_hu)\n",
    "    en_like = bigrams_in_word(w, bigram_counter_en)\n",
    "    i = bigram_selector(w, [bigram_counter_hu, bigram_counter_en], 0.60)\n",
    "    if (i == 0):\n",
    "        hu_w += 1\n",
    "    else:\n",
    "        if (i == 1):\n",
    "            en_w += 1\n",
    "        else:\n",
    "            idk_w += 1\n",
    "print(hu_w,en_w,idk_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMBMBMMMMMMMMMMMMMMMMMMMMMMMMM']\n"
     ]
    }
   ],
   "source": [
    "N = 1\n",
    "tests_result = model_cnn.predict(tests_input_cnn[0:N])\n",
    "test_ev = []\n",
    "for test in tests_result:\n",
    "    test_hardmax = np.argmax(test, axis=1)\n",
    "    word_tag = ''\n",
    "    for i in test_hardmax:\n",
    "        tag_list = np.array(list(tag_chars))\n",
    "        char_tag = tag_list[i]\n",
    "        word_tag += char_tag\n",
    "    test_ev.append(word_tag)\n",
    "print(test_ev)\n",
    "#print(tests_target_cnn[0:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [0,1]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
