{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pyphen\n",
    "import string\n",
    "import re\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypher = pyphen.Pyphen(lang='hu_HU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hyph_class(word, hypher=pyphen.Pyphen(lang='hu_HU'), aslist=False):\n",
    "    \"\"\"Hyphenating classification of the characters in the word. {B(egin),M(iddle),E(nd),S(ingle)}\"\"\"\n",
    "    if(len(word)==0):\n",
    "        raise IndexError(\"0 length word\")\n",
    "    ret = list('M' * len(word))\n",
    "    ret[0]='B'\n",
    "    ret[-1]='E'\n",
    "    for i in hypher.positions(word):\n",
    "        ret[i]='B'\n",
    "        if(ret[i-1]=='B'):\n",
    "            ret[i-1]='S'\n",
    "        else:\n",
    "            ret[i-1]='E'\n",
    "    if(aslist):\n",
    "        return ret\n",
    "    return \"\".join(ret)\n",
    "def same_char_num(word, hypher=pyphen.Pyphen(lang='hu_HU')):\n",
    "    \"\"\"Return true if the hyphenated word has as many chars as the original\"\"\"\n",
    "    return len(hypher.inserted(word))==len(word)+len(hypher.positions(word))\n",
    "def cleaning(data):\n",
    "    \"\"\"Text cleaning:\n",
    "        lower the letters\n",
    "        punctuation, digits ellimination\"\"\"\n",
    "    formated_data = data.lower()\n",
    "    formated_data = re.sub('['+string.punctuation+']','',formated_data)\n",
    "    formated_data = re.sub('['+string.digits+']','',formated_data)\n",
    "    return formated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter_hu_data = collections.Counter()\n",
    "word_list = []\n",
    "c_all = 0\n",
    "c_same_char_num = 0\n",
    "with open('web2.2-freq-sorted.txt','r',errors='ignore',encoding='latin2') as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        i = i+1\n",
    "        words = line.split()\n",
    "        if len(words)>1:\n",
    "            if(words[1].isdigit()):\n",
    "                counter_hu_data[cleaning(words[0])]+=int(words[1])\n",
    "        if i>100000:\n",
    "            break\n",
    "for words in counter_hu_data.most_common():\n",
    "    c_all+=1\n",
    "    next_word = words[0]\n",
    "    if(len(next_word)!=0 and same_char_num(next_word)):\n",
    "        c_same_char_num+=1\n",
    "        word_list.append([next_word,hyph_class(next_word)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867324640395745"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_same_char_num/c_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ember', 'BEBME'], ['ezek', 'BMME'], ['tovább', 'BEBMME'], ['vagyok', 'BEBMME'], ['ma', 'BE'], ['miatt', 'BEBME'], ['this', 'BMME'], ['mellett', 'BMEBMME'], ['vannak', 'BMEBME'], ['by', 'BE'], ['alapján', 'BMMEBME'], ['lenne', 'BMEBE'], ['with', 'BMME'], ['that', 'BMME'], ['tehát', 'BEBME'], ['te', 'BE'], ['it', 'BE'], ['ben', 'BME'], ['egész', 'BMMME'], ['néhány', 'BEBMME'], ['milyen', 'BEBMME'], ['át', 'BE'], ['nekem', 'BEBME'], ['előtt', 'BMMME'], ['ezzel', 'BEBME'], ['mivel', 'BEBME'], ['ezen', 'BMME'], ['nélkül', 'BMEBME'], ['lett', 'BMME'], ['stb', 'BME'], ['you', 'BME'], ['viszont', 'BEBMMME'], ['év', 'BE'], ['teljes', 'BMEBME'], ['erre', 'BEBE'], ['hiszen', 'BEBMME'], ['másik', 'BEBME'], ['ebben', 'BEBME'], ['mind', 'BMME'], ['der', 'BME'], ['három', 'BEBME'], ['talán', 'BEBME'], ['valami', 'BEBEBE'], ['die', 'BME'], ['bár', 'BME'], ['are', 'BME'], ['legyen', 'BEBMME'], ['tudom', 'BEBME'], ['from', 'BMME'], ['inkább', 'BEBMME'], ['során', 'BEBME'], ['például', 'BMEBEBE'], ['rá', 'BE'], ['m', 'E'], ['persze', 'BMEBME'], ['pl', 'BE'], ['mely', 'BMME'], ['azok', 'BMME'], ['áll', 'BME'], ['szerintem', 'BMEBMEBME'], ['miért', 'BEBME'], ['jelenleg', 'BEBMEBME'], ['aztán', 'BEBME'], ['c', 'E'], ['na', 'BE'], ['ft', 'BE'], ['európai', 'BEBEBME'], ['nagyobb', 'BEBMMME'], ['adott', 'BMMME'], ['akár', 'BMME'], ['elég', 'BMME'], ['se', 'BE'], ['éves', 'BMME'], ['fontos', 'BMEBME'], ['amelyek', 'BMEBMME'], ['együtt', 'BMMMME'], ['éppen', 'BEBME'], ['szükséges', 'BMMEBEBME'], ['hát', 'BME'], ['megfelelő', 'BMEBEBEBE'], ['őket', 'BMME'], ['neki', 'BEBE'], ['szó', 'BME'], ['program', 'BMMEBME'], ['nap', 'BME'], ['jobb', 'BMME'], ['további', 'BEBMEBE'], ['ahogy', 'BMMME'], ['teljesen', 'BMEBEBME'], ['hozzá', 'BMEBE'], ['következő', 'BEBMEBEBE'], ['maga', 'BEBE'], ['or', 'BE'], ['rt', 'BE'], ['egyes', 'BMMME'], ['benne', 'BMEBE'], ['esetén', 'BMEBME'], ['különböző', 'BEBMEBEBE'], ['belül', 'BEBME'], ['all', 'BME']]\n"
     ]
    }
   ],
   "source": [
    "print(word_list[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82181"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#onehot: {'B','M','E','S'}\n",
    "def one_hot_encode(char,dictionary='BMES'):\n",
    "    ret = [0]*len(dictionary)\n",
    "    if char in dictionary:\n",
    "        ret[dictionary.find(char)]=1\n",
    "        return ret\n",
    "    raise ValueError('Value out of dictionary range'+char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hun_chars='aábcdeéfghiíjklmnoóöőpqrstuúüűvwxyz'+'.'\n",
    "def generate_network_data(data, ret_input = [],ret_output=[],length = 2, start_char='.'):\n",
    "    \"\"\"from [word,hyph_class(word) to length-long input-output data\"\"\"\n",
    "    word = data[0]\n",
    "    word_plus = start_char*(length-1)+word\n",
    "    hyph_word = data[1]\n",
    "    for i in range(0,len(word)):\n",
    "        input_next_iter = []\n",
    "        for c in word_plus[i:i+length]:\n",
    "            input_next_iter.append(one_hot_encode(c,hun_chars))\n",
    "        output_next_iter = one_hot_encode(hyph_word[i])\n",
    "        ret_input.append(input_next_iter)\n",
    "        ret_output.append(output_next_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] [1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "wc_in=[]\n",
    "wc_out=[]\n",
    "\n",
    "generate_network_data(['alma','BEBE'],wc_in, wc_out)\n",
    "print(wc_in[0],wc_out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data len:  695849\n",
      "Wrong words:  640\n"
     ]
    }
   ],
   "source": [
    "data_in = []\n",
    "data_out = []\n",
    "wrong_word = 0\n",
    "for word in word_list:\n",
    "    try:\n",
    "        generate_network_data(word,data_in,data_out,2)\n",
    "    except ValueError:\n",
    "        wrong_word+=1\n",
    "print('Data len: ',len(data_in))\n",
    "print('Wrong words: ',wrong_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_length = 2\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_shape=(2,36), units=10, name='input_layer'))\n",
    "model.add(Dense(4,name='output_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(data_in[0:10],data_out[0:10], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 0],\n",
       " [1, 0, 0, 0],\n",
       " [0, 0, 1, 0],\n",
       " [1, 0, 0, 0],\n",
       " [0, 0, 1, 0],\n",
       " [1, 0, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 1, 0, 0],\n",
       " [0, 0, 1, 0],\n",
       " [1, 0, 0, 0]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
